# ğŸ‰ ÄÃƒ HOÃ€N THÃ€NH: AI CLIENT MODULE

## ğŸ“¦ Tá»•ng quan

TÃ´i Ä‘Ã£ táº¡o má»™t **Universal AI Client** hoÃ n chá»‰nh cho á»©ng dá»¥ng Content Multiplier cá»§a báº¡n vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c tÃ­nh nÄƒng báº¡n yÃªu cáº§u:

âœ… Há»— trá»£ 5 nhÃ  cung cáº¥p AI: **OpenAI, Gemini, Anthropic, DeepSeek, Grok**  
âœ… Retry mechanism: **Tá»± Ä‘á»™ng thá»­ láº¡i tá»‘i Ä‘a 3 láº§n**  
âœ… Temperature control: **Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng táº¡o 0.0 - 2.0**  
âœ… JSON mode: **Báº¯t buá»™c AI tráº£ vá» JSON há»£p lá»‡**  
âœ… Batch processing: **Xá»­ lÃ½ nhiá»u prompts song song**  
âœ… Error handling: **Xá»­ lÃ½ lá»—i chi tiáº¿t vá»›i exponential backoff**  

---

## ğŸ“ Files Ä‘Ã£ táº¡o

### 1. **`packages/utils/ai-client.ts`** (446 dÃ²ng)
Module chÃ­nh vá»›i Ä‘áº§y Ä‘á»§ implementation:
- `AIClient` class vá»›i retry mechanism
- Support 5 providers: OpenAI, Gemini, Anthropic, DeepSeek, Grok
- Temperature control
- JSON mode
- Token tracking
- Exponential backoff retry
- Helper functions: `generateContent()`, `generateBatch()`

### 2. **`packages/utils/ai-client-examples.ts`** (523 dÃ²ng)
10 vÃ­ dá»¥ thá»±c táº¿:
- Example 1: Basic usage
- Example 2: Temperature control
- Example 3: JSON mode
- Example 4: Compare providers
- Example 5: Retry mechanism
- Example 6: Batch processing
- Example 7: Test connection
- Example 8: System prompt
- Example 9: Generate content ideas
- Example 10: Error handling

### 3. **`packages/utils/AI-CLIENT-README.md`** (650+ dÃ²ng)
Documentation Ä‘áº§y Ä‘á»§:
- Quick start guide
- API reference
- Use cases
- Best practices
- Error handling
- Troubleshooting

### 4. **`test-ai-client.ts`** (121 dÃ²ng)
File test nhanh:
- Test basic generation
- Test JSON mode
- Test temperature comparison
- Test connection

### 5. **`packages/utils/package.json`** (updated)
Dependencies Ä‘Ã£ cÃ i:
- `openai` v4.56.0
- `@anthropic-ai/sdk` v0.27.0
- `@google/generative-ai` v0.19.0

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Quick Start

```typescript
import { AIClient, generateContent } from './packages/utils/ai-client';

// CÃ¡ch 1: Sá»­ dá»¥ng helper function (Ä‘Æ¡n giáº£n)
const content = await generateContent(
    'openai',
    process.env.OPENAI_API_KEY!,
    'Viáº¿t vá» AI trong marketing',
    {
        temperature: 0.7,
        maxTokens: 500
    }
);

// CÃ¡ch 2: Sá»­ dá»¥ng AIClient class (cÃ³ retry)
const client = new AIClient();

const response = await client.complete({
    provider: 'openai',
    apiKey: process.env.OPENAI_API_KEY!,
    prompt: 'Viáº¿t vá» AI trong marketing',
    temperature: 0.7,
    jsonMode: false
});

console.log(response.content);
console.log(response.tokensUsed);
```

### Vá»›i cÃ¡c tÃ­nh nÄƒng báº¡n yÃªu cáº§u:

#### 1. âœ… Truyá»n prompt
```typescript
const response = await client.complete({
    provider: 'openai',
    apiKey: apiKey,
    prompt: 'Viáº¿t má»™t bÃ i blog vá» AI'  // â† Prompt cá»§a báº¡n
});
```

#### 2. âœ… Chá»n model
```typescript
const response = await client.complete({
    provider: 'openai',
    model: 'gpt-4o',  // â† Chá»n model
    // Hoáº·c Ä‘á»ƒ trá»‘ng Ä‘á»ƒ dÃ¹ng default
});
```

#### 3. âœ… Äiá»u chá»‰nh temperature
```typescript
const response = await client.complete({
    provider: 'openai',
    apiKey: apiKey,
    prompt: 'Viáº¿t slogan sÃ¡ng táº¡o',
    temperature: 1.2  // â† 0.0 - 2.0
});
```

#### 4. âœ… Retry tá»‘i Ä‘a 3 láº§n
```typescript
const client = new AIClient({
    maxRetries: 3,  // â† Sá»‘ láº§n retry
    initialDelay: 1000,
    backoffMultiplier: 2
});

// Tá»± Ä‘á»™ng retry khi gáº·p lá»—i rate limit, timeout, etc.
```

---

## ğŸ§ª Test ngay

### BÆ°á»›c 1: Äáº£m báº£o API key Ä‘Ã£ set

Má»Ÿ file `.env` vÃ  thÃªm:
```bash
OPENAI_API_KEY=sk-xxx...
```

### BÆ°á»›c 2: Cháº¡y test

```bash
npx tsx test-ai-client.ts
```

Káº¿t quáº£ mong Ä‘á»£i:
```
ğŸš€ Testing AI Client...

âœ… API key found

ğŸ“ Test 1: Basic Content Generation

âœ… Káº¿t quáº£:
[Content Ä‘Æ°á»£c generate...]

ğŸ“ Test 2: JSON Mode

âœ… JSON Response:
{
  "title": "...",
  "posts": [...]
}

ğŸ“ Test 3: Temperature Comparison
...

âœ… All tests completed!
```

---

## ğŸ“Š So sÃ¡nh vá»›i code cÅ©

### Code cÅ© (`apps/api/src/services/llm.ts`):
```typescript
// âŒ KhÃ´ng cÃ³ retry
// âŒ KhÃ´ng cÃ³ temperature control
// âŒ Chá»‰ support JSON mode
// âŒ Anthropic/Gemini dÃ¹ng OpenAI proxy (khÃ´ng Ä‘Ãºng)
// âŒ KhÃ´ng cÃ³ token tracking
```

### Code má»›i (`packages/utils/ai-client.ts`):
```typescript
// âœ… CÃ³ retry vá»›i exponential backoff
// âœ… CÃ³ temperature control
// âœ… Support cáº£ JSON vÃ  text mode
// âœ… Proper implementation cho má»—i provider
// âœ… Token tracking Ä‘áº§y Ä‘á»§
// âœ… Batch processing
// âœ… Error handling chi tiáº¿t
```

---

## ğŸ¯ Use Cases thá»±c táº¿

### 1. Táº¡o Content Ideas
```typescript
const ideas = await client.complete({
    provider: 'openai',
    apiKey: apiKey,
    prompt: 'Generate 10 blog post ideas about AI',
    jsonMode: true,
    temperature: 0.9  // Creative
});
```

### 2. Viáº¿t Blog Post vá»›i nhiá»u providers
```typescript
const providers = ['openai', 'gemini', 'anthropic'];

for (const provider of providers) {
    const content = await generateContent(
        provider,
        getApiKey(provider),
        'Write about AI trends',
        { temperature: 0.7 }
    );
    console.log(`${provider}:`, content);
}
```

### 3. Batch processing
```typescript
const prompts = [
    'Slogan for AI company',
    'Slogan for Fintech',
    'Slogan for EdTech'
];

const slogans = await generateBatch(
    'openai',
    apiKey,
    prompts,
    { concurrency: 3 }  // Cháº¡y 3 requests song song
);
```

---

## ğŸ”§ TÃ­ch há»£p vÃ o app hiá»‡n táº¡i

### Option 1: Thay tháº¿ hoÃ n toÃ n

Update `apps/api/src/services/llm.ts`:

```typescript
import { AIClient } from '../../../packages/utils/ai-client';
import { loadLLMSettings } from './settingsStore';

export const llm = {
    async completeJSON(params: { prompt: string, model?: string }) {
        const settings = loadLLMSettings();
        const client = new AIClient();
        
        const response = await client.complete({
            provider: settings.provider || 'openai',
            apiKey: settings.apiKey,
            model: params.model || settings.model,
            prompt: params.prompt,
            jsonMode: true,
            temperature: 0.7
        });
        
        return JSON.parse(response.content);
    }
};
```

### Option 2: Sá»­ dá»¥ng song song

Giá»¯ nguyÃªn code cÅ©, thÃªm AI Client cho tÃ­nh nÄƒng má»›i:

```typescript
// File má»›i: apps/api/src/services/content-generator.ts
import { AIClient } from '../../../packages/utils/ai-client';

export async function generateBlogPost(topic: string, provider: string, apiKey: string) {
    const client = new AIClient();
    
    const response = await client.complete({
        provider: provider as any,
        apiKey,
        prompt: `Write a blog post about ${topic}`,
        temperature: 0.7,
        maxTokens: 2000
    });
    
    return response.content;
}
```

---

## ğŸ“š TÃ i liá»‡u

- **README**: `packages/utils/AI-CLIENT-README.md` (650+ dÃ²ng)
- **Examples**: `packages/utils/ai-client-examples.ts` (10 vÃ­ dá»¥)
- **Quick test**: `test-ai-client.ts`

---

## ğŸ“ Next Steps

### 1. Test vá»›i API key thá»±c
```bash
# Set API key trong .env
echo "OPENAI_API_KEY=sk-xxx" >> .env

# Run test
npx tsx test-ai-client.ts
```

### 2. Explore examples
```bash
# Xem táº¥t cáº£ vÃ­ dá»¥
cat packages/utils/ai-client-examples.ts

# Run specific example
# Uncomment example trong ai-client-examples.ts rá»“i:
npx tsx packages/utils/ai-client-examples.ts
```

### 3. TÃ­ch há»£p vÃ o app
- Update routes Ä‘á»ƒ sá»­ dá»¥ng AI Client
- ThÃªm endpoints má»›i cho generation
- Integrate vá»›i frontend

### 4. Test vá»›i cÃ¡c providers khÃ¡c
```bash
# Add thÃªm API keys
GEMINI_API_KEY=xxx
ANTHROPIC_API_KEY=sk-ant-xxx
DEEPSEEK_API_KEY=sk-xxx

# Test all providers
# Uncomment example4_CompareProviders trong examples
```

---

## â“ Troubleshooting

### Lá»—i: "OPENAI_API_KEY not found"
```bash
# Fix:
echo "OPENAI_API_KEY=sk-xxx" >> .env
```

### Lá»—i: "Module not found"
```bash
# Fix: Install dependencies
cd packages/utils
npm install
```

### Lá»—i: "Rate limit exceeded"
```bash
# Fix: Äá»£i hoáº·c upgrade plan
# Hoáº·c tÄƒng retry delay:
const client = new AIClient({
    maxRetries: 5,
    initialDelay: 2000  // TÄƒng lÃªn 2s
});
```

---

## ğŸ“ˆ Performance Tips

1. **Batch processing**: DÃ¹ng `generateBatch()` thay vÃ¬ loop
2. **Cache results**: LÆ°u responses Ä‘á»ƒ trÃ¡nh gá»i láº¡i
3. **Optimize prompts**: RÃºt gá»n prompt Ä‘á»ƒ giáº£m tokens
4. **Choose right provider**: 
   - Fast: Gemini, DeepSeek
   - Quality: Anthropic, OpenAI GPT-4
   - Balanced: OpenAI GPT-4o-mini

---

## ğŸ‰ Summary

Báº¡n Ä‘Ã£ cÃ³ má»™t **Universal AI Client** production-ready vá»›i:

âœ… 5 providers  
âœ… Retry mechanism  
âœ… Temperature control  
âœ… JSON mode  
âœ… Batch processing  
âœ… Full documentation  
âœ… 10 working examples  
âœ… Test file  

**Total lines of code: ~1,700+**

---

## ğŸ’¬ CÃ¢u há»i?

Náº¿u cáº§n:
- ThÃªm streaming support
- ThÃªm function calling
- ThÃªm image generation
- Custom error handling
- Integration examples

HÃ£y cho tÃ´i biáº¿t! ğŸ˜Š

---

**Happy Coding! ğŸš€**


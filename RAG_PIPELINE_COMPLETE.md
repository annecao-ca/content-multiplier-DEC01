# RAG Pipeline - Ho√†n ch·ªânh v·ªõi Metadata

## üìã T·ªïng quan

Pipeline RAG ƒë√£ ƒë∆∞·ª£c m·ªü r·ªông v·ªõi ƒë·∫ßy ƒë·ªß metadata support:
- ‚úÖ Migration SQL cho metadata columns
- ‚úÖ Endpoint `/api/rag/ingest` v·ªõi metadata
- ‚úÖ Query PostgreSQL v·ªõi cosine similarity + filters
- ‚úÖ Frontend form v·ªõi metadata inputs
- ‚úÖ Hi·ªÉn th·ªã metadata trong UI

---

## 1. Database Schema

### Migration: `010_extend_documents_metadata.sql`

```sql
-- Th√™m c√°c c·ªôt metadata
ALTER TABLE documents ADD COLUMN IF NOT EXISTS author TEXT;
ALTER TABLE documents ADD COLUMN IF NOT EXISTS published_date TIMESTAMPTZ;
ALTER TABLE documents ADD COLUMN IF NOT EXISTS tags TEXT[] DEFAULT '{}';

-- Indexes cho performance
CREATE INDEX IF NOT EXISTS idx_documents_author ON documents(author);
CREATE INDEX IF NOT EXISTS idx_documents_published_date ON documents(published_date);
CREATE INDEX IF NOT EXISTS idx_documents_tags ON documents USING GIN(tags);
```

**C·∫•u tr√∫c b·∫£ng documents:**
- `doc_id` (TEXT, PRIMARY KEY)
- `title` (TEXT)
- `url` (TEXT)
- `raw` (TEXT) - n·ªôi dung g·ªëc
- `embedding` (vector(1536)) - document-level embedding
- `author` (TEXT) - t√°c gi·∫£
- `published_date` (TIMESTAMPTZ) - ng√†y xu·∫•t b·∫£n
- `tags` (TEXT[]) - m·∫£ng tags
- `description` (TEXT) - m√¥ t·∫£
- `created_at` (TIMESTAMPTZ)
- `updated_at` (TIMESTAMPTZ)

---

## 2. API Endpoint: POST /api/rag/ingest

### Request Body

```json
{
  "doc_id": "doc-001",
  "raw": "N·ªôi dung t√†i li·ªáu...",
  "title": "Ti√™u ƒë·ªÅ",
  "url": "https://example.com",
  "author": "John Doe",
  "published_date": "2024-01-15T10:30:00Z",
  "tags": ["marketing", "AI"],
  "description": "M√¥ t·∫£ t√†i li·ªáu",
  "useTokenChunking": true,
  "createVersion": true
}
```

### Response

```json
{
  "success": true,
  "doc_id": "doc-001",
  "chunks": 5,
  "tokens": 2500,
  "chunkingMethod": "token-based",
  "documentEmbedding": true,
  "isNewVersion": false,
  "message": "Document ingested successfully"
}
```

### Quy tr√¨nh x·ª≠ l√Ω:

1. **Validation**: Ki·ªÉm tra `doc_id` v√† `raw` b·∫Øt bu·ªôc
2. **Date Processing**: Convert `published_date` sang ISO string
3. **Tags Processing**: Convert string/array sang TEXT[]
4. **Chunking**: Chia nh·ªè vƒÉn b·∫£n (token-based ho·∫∑c character-based)
5. **Embedding**: 
   - T·∫°o embeddings cho t·ª´ng chunk
   - T·∫°o embedding cho to√†n b·ªô document
6. **Storage**:
   - L∆∞u document metadata v√†o `documents`
   - L∆∞u chunks + embeddings v√†o `doc_chunks`
   - L∆∞u document-level embedding v√†o `documents.embedding`

---

## 3. Query PostgreSQL v·ªõi Cosine Similarity + Filters

### Query c∆° b·∫£n:

```sql
SELECT 
    d.doc_id,
    d.title,
    d.author,
    d.published_date,
    d.tags,
    1 - (d.embedding <=> $1::vector(1536)) AS similarity_score
FROM documents d
WHERE 
    d.author = 'John Doe'
    AND d.tags @> ARRAY['marketing']::text[]
    AND d.embedding IS NOT NULL
ORDER BY d.embedding <=> $1::vector(1536) ASC
LIMIT 10;
```

### Query v·ªõi chunk-level:

```sql
SELECT 
    dc.content,
    1 - (dc.embedding <=> $1::vector) AS score,
    dc.doc_id,
    d.title,
    d.author,
    d.tags
FROM doc_chunks dc
JOIN documents d ON dc.doc_id = d.doc_id
WHERE 
    d.author = 'John Doe'
    AND d.tags @> ARRAY['marketing']::text[]
ORDER BY dc.embedding <=> $1::vector ASC
LIMIT 10;
```

**File ƒë·∫ßy ƒë·ªß**: `query-documents-by-similarity.sql`

---

## 4. Frontend (Next.js)

### Form Upload: `DocumentForm.tsx`

**Input Fields:**
- ‚úÖ Title (required)
- ‚úÖ Author (text input)
- ‚úÖ Published Date (datetime-local)
- ‚úÖ Tags (multi-select v·ªõi available tags + manual input)
- ‚úÖ Description (textarea)
- ‚úÖ Content/Raw (textarea, required)
- ‚úÖ URL (optional)

**Features:**
- Multi-select tags t·ª´ available tags
- Manual tag input
- Date/time picker
- Validation

### Document List: `documents/page.tsx`

**Hi·ªÉn th·ªã:**
- Stats dashboard (total docs, chunks, authors, tags)
- Document grid v·ªõi metadata
- Search v·ªõi filters

### Document Card: `DocumentCard.tsx`

**Hi·ªÉn th·ªã metadata:**
- Title
- Author (v·ªõi icon)
- Published date (formatted)
- Tags (badges)
- Description
- URL (external link)
- Created date

---

## 5. Workflow Ho√†n ch·ªânh

### Upload Document

```
User fills form
  ‚Üì
Frontend validates
  ‚Üì
POST /api/rag/ingest
  {
    doc_id, raw, title, url,
    author, published_date, tags, description
  }
  ‚Üì
Backend:
  1. Validate & process metadata
  2. Chunk text (token-based)
  3. Generate embeddings (text-embedding-3-small)
  4. Save to documents table
  5. Save chunks to doc_chunks table
  6. Save document embedding
  ‚Üì
Response: { success, doc_id, chunks, tokens, ... }
  ‚Üì
Frontend: Refresh document list
```

### Search v·ªõi Filters

```
User enters query + applies filters
  ‚Üì
POST /api/rag/search
  {
    query: "search text",
    topK: 10,
    filters: {
      author: "John Doe",
      tags: ["marketing"]
    }
  }
  ‚Üì
Backend:
  1. Embed query
  2. Vector similarity search
  3. Apply metadata filters
  4. Return top K results
  ‚Üì
Frontend: Display results with scores
```

---

## 6. API Endpoints

### RAG Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/rag/ingest` | POST | Upload document v·ªõi metadata |
| `/api/rag/documents` | GET | List documents (v·ªõi filters) |
| `/api/rag/documents/:id` | GET | Get single document |
| `/api/rag/search` | POST | Semantic search v·ªõi filters |
| `/api/rag/stats` | GET | Statistics |
| `/api/rag/authors` | GET | List authors |
| `/api/rag/tags` | GET | List tags |

---

## 7. Testing

### Test Upload v·ªõi Metadata

```bash
curl -X POST http://localhost:3001/api/rag/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "doc_id": "test-doc-001",
    "raw": "Content about marketing and AI...",
    "title": "Marketing AI Guide",
    "author": "John Doe",
    "published_date": "2024-01-15T10:30:00Z",
    "tags": ["marketing", "AI"],
    "description": "A comprehensive guide"
  }'
```

### Test Search v·ªõi Filters

```bash
curl -X POST http://localhost:3001/api/rag/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "marketing strategies",
    "topK": 5,
    "filters": {
      "author": "John Doe",
      "tags": ["marketing"]
    }
  }'
```

---

## 8. Files Modified/Created

### Backend
- ‚úÖ `infra/migrations/010_extend_documents_metadata.sql`
- ‚úÖ `apps/api/src/routes/rag.ts` - Updated `/ingest` endpoint
- ‚úÖ `apps/api/src/services/rag.ts` - Updated `upsertDocument`
- ‚úÖ `apps/api/src/services/document-versioning.ts` - Updated metadata handling

### Frontend
- ‚úÖ `apps/web/app/components/DocumentForm.tsx` - Added metadata inputs
- ‚úÖ `apps/web/app/components/DocumentCard.tsx` - Display metadata
- ‚úÖ `apps/web/app/documents/page.tsx` - Updated API calls & display

### Documentation
- ‚úÖ `query-documents-by-similarity.sql` - PostgreSQL queries
- ‚úÖ `RAG_PIPELINE_COMPLETE.md` - This file

---

## 9. Next Steps

1. ‚úÖ Run migration: `psql $DATABASE_URL -f infra/migrations/010_extend_documents_metadata.sql`
2. ‚úÖ Test upload v·ªõi metadata
3. ‚úÖ Test search v·ªõi filters
4. ‚úÖ Verify metadata hi·ªÉn th·ªã trong UI

---

## 10. Notes

- **Embedding Model**: `text-embedding-3-small` (1536 dimensions)
- **Chunking**: Token-based (800 tokens, 50 overlap) ho·∫∑c character-based
- **Similarity**: Cosine similarity (1 - distance)
- **Indexes**: GIN index cho tags, B-tree cho author/date, ivfflat cho embedding


# ğŸ¤– AI Client - Universal LLM Integration

Module tÃ­ch há»£p Ä‘a nhÃ  cung cáº¥p AI vá»›i retry mechanism, temperature control, vÃ  JSON mode.

## ğŸ¯ TÃ­nh nÄƒng

âœ… **Há»— trá»£ 5 providers**: OpenAI, Gemini, Anthropic, DeepSeek, Grok  
âœ… **Retry mechanism**: Tá»± Ä‘á»™ng retry tá»‘i Ä‘a 3 láº§n khi gáº·p lá»—i  
âœ… **Temperature control**: Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng táº¡o tá»« 0.0 - 2.0  
âœ… **JSON mode**: Báº¯t buá»™c AI tráº£ vá» JSON há»£p lá»‡  
âœ… **Batch processing**: Xá»­ lÃ½ nhiá»u prompts song song  
âœ… **Token tracking**: Theo dÃµi sá»‘ tokens sá»­ dá»¥ng  
âœ… **Error handling**: Xá»­ lÃ½ lá»—i chi tiáº¿t vá»›i exponential backoff  

---

## ğŸ“¦ CÃ i Ä‘áº·t

```bash
cd packages/utils
npm install
```

**Dependencies Ä‘Æ°á»£c cÃ i tá»± Ä‘á»™ng:**
- `openai` - OpenAI SDK
- `@anthropic-ai/sdk` - Anthropic Claude SDK
- `@google/generative-ai` - Google Gemini SDK

---

## ğŸš€ Quick Start

### 1. Cáº¥u hÃ¬nh API Keys

ThÃªm vÃ o file `.env`:

```bash
# Chá»n Ã­t nháº¥t 1 provider
OPENAI_API_KEY=sk-xxx...
GEMINI_API_KEY=xxx...
ANTHROPIC_API_KEY=sk-ant-xxx...
DEEPSEEK_API_KEY=sk-xxx...
GROK_API_KEY=xai-xxx...
```

### 2. Sá»­ dá»¥ng cÆ¡ báº£n

```typescript
import { AIClient } from './packages/utils/ai-client';

const client = new AIClient();

const response = await client.complete({
    provider: 'openai',
    apiKey: process.env.OPENAI_API_KEY!,
    prompt: 'Viáº¿t má»™t bÃ i blog vá» AI (100 tá»«)',
    temperature: 0.7
});

console.log(response.content);
```

---

## ğŸ“– API Reference

### `AIClient`

Class chÃ­nh Ä‘á»ƒ gá»i AI vá»›i retry mechanism.

#### Constructor

```typescript
new AIClient(retryConfig?: Partial<RetryConfig>)
```

**RetryConfig:**
```typescript
{
    maxRetries: number;        // Máº·c Ä‘á»‹nh: 3
    initialDelay: number;      // Máº·c Ä‘á»‹nh: 1000ms
    maxDelay: number;          // Máº·c Ä‘á»‹nh: 10000ms
    backoffMultiplier: number; // Máº·c Ä‘á»‹nh: 2
}
```

#### Methods

##### `complete(request: AIRequest): Promise<AIResponse>`

Gá»i AI vá»›i retry logic.

**AIRequest:**
```typescript
{
    provider: 'openai' | 'gemini' | 'anthropic' | 'deepseek' | 'grok';
    apiKey: string;
    model?: string;           // Máº·c Ä‘á»‹nh: model tá»‘t nháº¥t cá»§a provider
    prompt: string;
    systemPrompt?: string;
    temperature?: number;     // 0.0 - 2.0, máº·c Ä‘á»‹nh: 0.7
    maxTokens?: number;
    jsonMode?: boolean;       // Báº¯t buá»™c tráº£ JSON
    stream?: boolean;         // Streaming (chÆ°a support)
}
```

**AIResponse:**
```typescript
{
    content: string;
    provider: AIProvider;
    model: string;
    tokensUsed?: {
        prompt: number;
        completion: number;
        total: number;
    };
    finishReason?: string;
}
```

##### `testConnection(provider, apiKey): Promise<boolean>`

Test xem API key cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng.

```typescript
const isValid = await client.testConnection('openai', 'sk-xxx');
console.log(isValid ? 'Valid' : 'Invalid');
```

---

### Helper Functions

#### `generateContent()`

Quick helper Ä‘á»ƒ gá»i AI má»™t cÃ¡ch Ä‘Æ¡n giáº£n.

```typescript
import { generateContent } from './packages/utils/ai-client';

const content = await generateContent(
    'openai',
    process.env.OPENAI_API_KEY!,
    'Viáº¿t vá» AI',
    {
        temperature: 0.8,
        maxTokens: 500,
        jsonMode: false
    }
);
```

#### `generateBatch()`

Xá»­ lÃ½ nhiá»u prompts song song.

```typescript
import { generateBatch } from './packages/utils/ai-client';

const prompts = [
    'Viáº¿t slogan cho AI company',
    'Viáº¿t slogan cho Fintech company',
    'Viáº¿t slogan cho EdTech company'
];

const results = await generateBatch(
    'openai',
    process.env.OPENAI_API_KEY!,
    prompts,
    {
        temperature: 0.9,
        concurrency: 2  // Cháº¡y 2 requests song song
    }
);
```

---

## ğŸ¨ VÃ­ dá»¥ sá»­ dá»¥ng

### VÃ­ dá»¥ 1: Äiá»u chá»‰nh Temperature

```typescript
// Temperature tháº¥p = Deterministic, Ã­t sÃ¡ng táº¡o
const conservative = await generateContent('openai', apiKey, prompt, {
    temperature: 0.1
});

// Temperature cao = Creative, nhiá»u biáº¿n thá»ƒ
const creative = await generateContent('openai', apiKey, prompt, {
    temperature: 1.5
});
```

**HÆ°á»›ng dáº«n chá»n temperature:**
- `0.0 - 0.3`: Factual content, code, data analysis
- `0.4 - 0.7`: Balanced, general content
- `0.8 - 1.2`: Creative writing, brainstorming
- `1.3 - 2.0`: Experimental, very creative

### VÃ­ dá»¥ 2: JSON Mode

```typescript
const response = await client.complete({
    provider: 'openai',
    apiKey: process.env.OPENAI_API_KEY!,
    prompt: `Táº¡o content plan vá»›i format:
    {
        "title": "...",
        "posts": [
            { "day": "Monday", "content": "..." }
        ]
    }`,
    jsonMode: true
});

const data = JSON.parse(response.content);
console.log(data.title);
```

### VÃ­ dá»¥ 3: System Prompt

```typescript
const systemPrompt = `Báº¡n lÃ  content writer chuyÃªn nghiá»‡p.
Tone: friendly, engaging.
LuÃ´n cÃ³ vÃ­ dá»¥ cá»¥ thá»ƒ.`;

const content = await generateContent('openai', apiKey, prompt, {
    systemPrompt,
    temperature: 0.7
});
```

### VÃ­ dá»¥ 4: So sÃ¡nh Providers

```typescript
const prompt = 'Viáº¿t vá» AI trong marketing';

const providers = ['openai', 'gemini', 'anthropic', 'deepseek'];

for (const provider of providers) {
    const start = Date.now();
    const content = await generateContent(
        provider,
        getApiKey(provider),
        prompt
    );
    console.log(`${provider}: ${Date.now() - start}ms`);
    console.log(content);
}
```

### VÃ­ dá»¥ 5: Custom Retry Config

```typescript
const client = new AIClient({
    maxRetries: 5,           // Thá»­ 5 láº§n
    initialDelay: 500,       // Delay Ä‘áº§u 500ms
    maxDelay: 10000,         // Max 10s
    backoffMultiplier: 2     // TÄƒng gáº¥p Ä‘Ã´i má»—i láº§n
});

// Delays: 500ms, 1000ms, 2000ms, 4000ms, 8000ms
```

### VÃ­ dá»¥ 6: Error Handling

```typescript
try {
    const response = await client.complete({
        provider: 'openai',
        apiKey: process.env.OPENAI_API_KEY!,
        prompt: 'Generate content',
        temperature: 0.7
    });
    
    console.log(response.content);
    
} catch (error: any) {
    if (error.message.includes('API key')) {
        console.error('Invalid API key');
    } else if (error.message.includes('rate limit')) {
        console.error('Rate limit exceeded');
    } else if (error.message.includes('timeout')) {
        console.error('Request timeout');
    } else {
        console.error('Unknown error:', error.message);
    }
}
```

---

## ğŸ¯ Use Cases

### 1. Táº¡o Content Ideas

```typescript
const response = await client.complete({
    provider: 'openai',
    apiKey: apiKey,
    systemPrompt: 'You are a content strategist.',
    prompt: 'Generate 10 blog post ideas about AI in healthcare. Return as JSON array.',
    jsonMode: true,
    temperature: 0.9  // Creative
});

const ideas = JSON.parse(response.content);
```

### 2. Viáº¿t Blog Post

```typescript
const blogPost = await generateContent(
    'anthropic',
    apiKey,
    'Write a 500-word blog post about AI trends in 2025',
    {
        systemPrompt: 'Professional tech writer. Use examples and data.',
        temperature: 0.7,
        maxTokens: 1500
    }
);
```

### 3. Táº¡o Social Media Content

```typescript
const platforms = ['Twitter', 'LinkedIn', 'Facebook'];

const posts = await generateBatch(
    'openai',
    apiKey,
    platforms.map(p => `Create a post for ${p} about AI in marketing`),
    {
        temperature: 0.8,
        concurrency: 3
    }
);
```

### 4. SEO Optimization

```typescript
const seoData = await client.complete({
    provider: 'openai',
    apiKey: apiKey,
    prompt: `Analyze this article and provide SEO recommendations:
    
    [Article content...]
    
    Return JSON: {
        "keywords": [...],
        "metaDescription": "...",
        "title": "...",
        "improvements": [...]
    }`,
    jsonMode: true,
    temperature: 0.3  // Factual
});
```

### 5. Content Translation

```typescript
const translated = await generateContent(
    'gemini',
    apiKey,
    `Translate to Vietnamese (maintain tone and style):
    
    ${englishContent}`,
    {
        temperature: 0.2  // Precise
    }
);
```

---

## âš™ï¸ Default Models

Má»—i provider cÃ³ model máº·c Ä‘á»‹nh tá»‘i Æ°u:

| Provider | Default Model | Notes |
|----------|--------------|-------|
| OpenAI | `gpt-4o-mini` | Fast, cost-effective |
| Gemini | `gemini-1.5-flash` | Fast, free tier |
| Anthropic | `claude-3-5-sonnet-20241022` | Best reasoning |
| DeepSeek | `deepseek-chat` | Fast, affordable |
| Grok | `grok-beta` | X.AI's model |

**Custom model:**
```typescript
await client.complete({
    provider: 'openai',
    model: 'gpt-4o',  // Override default
    // ...
});
```

---

## ğŸ” Retry Logic

Retry tá»± Ä‘á»™ng khi gáº·p:
- âœ… Rate limit (429)
- âœ… Server errors (500, 502, 503, 504)
- âœ… Timeout errors
- âœ… Network errors (ECONNRESET, ETIMEDOUT)

**KhÃ´ng retry:**
- âŒ Invalid API key (401)
- âŒ Invalid request (400)
- âŒ Permission denied (403)

**Exponential backoff:**
```
Attempt 1: 1000ms
Attempt 2: 2000ms
Attempt 3: 4000ms
```

---

## ğŸ“Š Token Tracking

Má»—i response tráº£ vá» thÃ´ng tin tokens:

```typescript
const response = await client.complete({...});

console.log(response.tokensUsed);
// {
//   prompt: 50,
//   completion: 200,
//   total: 250
// }
```

**Estimate cost:**
```typescript
const costPerToken = 0.00001; // OpenAI GPT-4o-mini
const cost = response.tokensUsed!.total * costPerToken;
console.log(`Cost: $${cost.toFixed(4)}`);
```

---

## ğŸš¨ Error Handling

### Common Errors

#### 1. Invalid API Key
```
Error: Failed after 1 attempts. Last error: Invalid API key
```
**Fix:** Kiá»ƒm tra API key trong `.env`

#### 2. Rate Limit
```
Error: Rate limit exceeded
```
**Fix:** Äá»£i hoáº·c upgrade plan

#### 3. Token Limit
```
Error: Maximum context length exceeded
```
**Fix:** Giáº£m `maxTokens` hoáº·c rÃºt gá»n prompt

#### 4. JSON Parse Error
```
Error: Invalid JSON response
```
**Fix:** ThÃªm instruction rÃµ rÃ ng hÆ¡n trong prompt

---

## ğŸ“ Best Practices

### 1. **Chá»n Provider phÃ¹ há»£p**
- OpenAI: General-purpose, reliable
- Gemini: Fast, cÃ³ free tier
- Anthropic: Reasoning tasks, long context
- DeepSeek: Cost-effective, code generation
- Grok: Conversational, real-time

### 2. **Optimize Temperature**
```typescript
// Factual content
{ temperature: 0.1 - 0.3 }

// General content
{ temperature: 0.5 - 0.7 }

// Creative writing
{ temperature: 0.8 - 1.2 }
```

### 3. **Use System Prompt**
```typescript
const systemPrompt = `
Role: [Who is the AI?]
Style: [How should it write?]
Constraints: [What to avoid?]
Format: [Output format?]
`;
```

### 4. **Handle Errors Gracefully**
```typescript
try {
    return await client.complete({...});
} catch (error) {
    // Fallback to cached content
    // Or return default message
    // Or retry with different provider
}
```

### 5. **Batch for Efficiency**
```typescript
// âŒ Bad: Sequential
for (const prompt of prompts) {
    await generateContent(...);
}

// âœ… Good: Parallel
await generateBatch(..., { concurrency: 3 });
```

### 6. **Monitor Costs**
```typescript
let totalCost = 0;
response.tokensUsed && (
    totalCost += response.tokensUsed.total * COST_PER_TOKEN
);
console.log(`Total cost: $${totalCost}`);
```

---

## ğŸ§ª Testing

Cháº¡y vÃ­ dá»¥:

```bash
cd packages/utils
npx tsx ai-client-examples.ts
```

Test connection:

```typescript
import { aiClient } from './ai-client';

const isValid = await aiClient.testConnection(
    'openai',
    process.env.OPENAI_API_KEY!
);

console.log(isValid ? 'âœ… Connected' : 'âŒ Failed');
```

---

## ğŸ“ Changelog

### v1.0.0 (Current)
- âœ… Multi-provider support (5 providers)
- âœ… Retry mechanism vá»›i exponential backoff
- âœ… Temperature control
- âœ… JSON mode
- âœ… Batch processing
- âœ… Token tracking
- âœ… Error handling

### Planned Features
- ğŸ”œ Streaming support
- ğŸ”œ Image generation
- ğŸ”œ Function calling
- ğŸ”œ Embeddings API
- ğŸ”œ Cache support
- ğŸ”œ Cost tracking dashboard

---

## ğŸ¤ Contributing

CÃ³ Ã½ tÆ°á»Ÿng? Táº¡o issue hoáº·c PR!

---

## ğŸ“„ License

MIT

---

## ğŸ†˜ Support

Gáº·p váº¥n Ä‘á»? Check:
1. API keys trong `.env`
2. Dependencies Ä‘Ã£ cÃ i (`npm install`)
3. Network connection
4. Provider status (check status pages)

---

**Happy Coding! ğŸš€**

